{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../../data/customDatasets/paired_concatenated.tsv\", sep='\\t', low_memory=False)\n",
    "paired_output_folder = \"../../data/splitted_data/paired\"\n",
    "paired_seen_all_path = f\"{paired_output_folder}/seen_all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the data entries (without negative data) is analysed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcr_key = \"tcr_key\"\n",
    "\n",
    "df[tcr_key] = df['TRA_CDR3'].astype(str) + '_' + df['TRB_CDR3'].astype(str)\n",
    "\n",
    "\n",
    "distinct_tcrs = df.drop_duplicates(subset=[tcr_key], keep=\"first\", inplace=False)\n",
    "unique_epitopes = df.drop_duplicates(subset=[\"Epitope\"], keep=False, inplace=False)\n",
    "unique_tcrs = df.drop_duplicates(subset=[tcr_key], keep=False, inplace=False)\n",
    "\n",
    "\n",
    "print(f\"distinct tcr's: {len(distinct_tcrs)} from {len(df)}\")\n",
    "print(f\"unique tcr's: {len(unique_tcrs)} from {len(df)}\")\n",
    "print(f\"unique epitopes: {len(unique_epitopes[\"Epitope\"])} from {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a train and test set is created. The test set should consist only of TPP2 and TPP3 Tasks (TPP => TCRâ€“Peptide/Epitope Pairing).\n",
    "TPP2 means the epitope is seen in training but TCR is unseen.\n",
    "TPP3 means neither the TCR nor the epitope is seen in training ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df, unique_tcrs, how='left', indicator=True)\n",
    "df_train = df_train[df_train['_merge'] == 'left_only']\n",
    "df_train.drop(columns=[\"_merge\"])\n",
    "df_train[\"task\"] = \"\"\n",
    "train_epitopes = set(df_train[\"Epitope\"])\n",
    "\n",
    "df_test = unique_tcrs.copy()\n",
    "df_test[\"task\"] = df_test[\"Epitope\"].apply(lambda x: 'TPP3' if x not in train_epitopes else 'TPP2')\n",
    "\n",
    "\n",
    "number_of_TPP3 = (df_test['task'] == 'TPP3').sum()\n",
    "number_of_TPP2 = (df_test['task'] == 'TPP2').sum()\n",
    "test_ratio = len(df_test)/(len(df_test) + len(df_train))\n",
    "\n",
    "print(f\"train data has {len(df_train)} entries\")\n",
    "print(f\"test data has {len(df_test)} entries\")\n",
    "print(f\"test data has {number_of_TPP3} TPP3 tasks (unseen tcr & unseen epitope).\")\n",
    "print(f\"test data has {number_of_TPP2} TPP2 tasks (unseen tcr & seen epitopes).\")\n",
    "print(f\"the train/test ratio is {(1-test_ratio)}/{test_ratio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if the test ratio is below 0.3, we fill up the test data with TPP1 tasks (seen tcr & seen epitope). If the ratio is higher than 0.3, an exception get's thrown to prevent working with unbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "aimed_test_ratio = 0.3\n",
    "\n",
    "if(test_ratio > aimed_test_ratio):\n",
    "  raise Exception(\"The train/test ratio is too unbalanced.\")\n",
    "elif(test_ratio < aimed_test_ratio):\n",
    "  missing_test_data_count = math.ceil((aimed_test_ratio - test_ratio) * (len(df_test) + len(df_train)))\n",
    "  print(f\"{missing_test_data_count} entries need to be shifted from train to test so the train/test ratio can be {1-aimed_test_ratio}/{aimed_test_ratio}\")\n",
    "\n",
    "  for i in range(missing_test_data_count):\n",
    "    # Find values that appear more than once in each column\n",
    "    non_unique_epitopes = df_train['Epitope'].value_counts()\n",
    "    non_unique_epitopes = non_unique_epitopes[non_unique_epitopes > 1].index.tolist()\n",
    "\n",
    "    non_unique_TRA_CDR3 = df_train['TRA_CDR3'].value_counts()\n",
    "    non_unique_TRA_CDR3 = non_unique_TRA_CDR3[non_unique_TRA_CDR3 > 1].index.tolist()\n",
    "\n",
    "    non_unique_TRB_CDR3 = df_train['TRB_CDR3'].value_counts()\n",
    "    non_unique_TRB_CDR3 = non_unique_TRB_CDR3[non_unique_TRB_CDR3 > 1].index.tolist()\n",
    "\n",
    "    # Filter df_train to only include rows where the Epitope and CDR3 values are not unique\n",
    "    filtered_df = df_train[df_train['Epitope'].isin(non_unique_epitopes) & df_train['TRA_CDR3'].isin(non_unique_TRA_CDR3) & df_train['TRB_CDR3'].isin(non_unique_TRB_CDR3)]\n",
    "    \n",
    "    if not filtered_df.empty:\n",
    "      first_row_index = filtered_df.index[0]\n",
    "      df_train.loc[first_row_index, 'task'] = \"TPP1\"\n",
    "      # Append this row to df_test\n",
    "      df_test = pd.concat([df_test, pd.DataFrame([df_train.loc[first_row_index]])], ignore_index=True)\n",
    "      # Drop this row from df_train using its index\n",
    "      df_train = df_train.drop(first_row_index)\n",
    "    else:\n",
    "      raise Exception(\"The specific row does not exist in df_train.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_TPP1 = (df_test['task'] == 'TPP1').sum()\n",
    "number_of_TPP2 = (df_test['task'] == 'TPP2').sum()\n",
    "number_of_TPP3 = (df_test['task'] == 'TPP3').sum()\n",
    "test_ratio = len(df_test)/(len(df_test) + len(df_train))\n",
    "\n",
    "print(f\"train data has {len(df_train)} entries\")\n",
    "print(f\"test data has {len(df_test)} entries\")\n",
    "print(f\"test data has {number_of_TPP1} TPP1 tasks (unseen tcr & seen epitopes).\")\n",
    "print(f\"test data has {number_of_TPP2} TPP2 tasks (unseen tcr & seen epitopes).\")\n",
    "print(f\"test data has {number_of_TPP3} TPP3 tasks (unseen tcr & unseen epitope).\")\n",
    "print(f\"the train/test ratio is {(1-test_ratio)}/{test_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(columns=[\"_merge\", \"tcr_key\"], inplace=True)\n",
    "df_train.drop(columns=[\"_merge\", \"tcr_key\"], inplace=True)\n",
    "\n",
    "df_test.to_csv(paired_output_folder+\"/test.tsv\", sep=\"\\t\")\n",
    "df_train.to_csv(paired_output_folder+\"/train.tsv\", sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BA24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
