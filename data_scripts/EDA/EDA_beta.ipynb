{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA beta concatenated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we do some cleaning of the dataset because there are some unused and alpha-chain specific columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import wandb\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# W&B Setup\n",
    "# -----------------------------------------------------------------------------\n",
    "load_dotenv()\n",
    "PROJECT_NAME = os.getenv(\"MAIN_PROJECT_NAME\")\n",
    "print(f\"PROJECT_NAME: {PROJECT_NAME}\")\n",
    "run = wandb.init(project=PROJECT_NAME, job_type=f\"download dataset\", entity=\"ba-zhaw\")\n",
    "config = wandb.config\n",
    "\n",
    "\n",
    "# Download corresponding artifact (= dataset) from W&B\n",
    "precision = \"gene\" # gene or allele\n",
    "levenshtein_data_path = f\"/home/ubuntu/BA_ZHAW/data/EDA/beta/\"\n",
    "download_path = \"/home/ubuntu/BA_ZHAW/data/WnB_Download/beta\"\n",
    "output_path = f'/home/ubuntu/BA_ZHAW/data/EDA/beta/'\n",
    "output_file_name = f'beta_{precision}_levenshtein.tsv'\n",
    "dataset_name = f\"beta_{precision}\"\n",
    "artifact = run.use_artifact(f\"{dataset_name}:latest\")\n",
    "data_dir = artifact.download(download_path)\n",
    "\n",
    "run.finish()\n",
    "\n",
    "train_file_path = f\"{data_dir}/{precision}/train.tsv\"\n",
    "test_file_path = f\"{data_dir}/{precision}/test.tsv\"\n",
    "val_file_path = f\"{data_dir}/{precision}/validation.tsv\"\n",
    "\n",
    "df_train = pd.read_csv(train_file_path, sep=\"\\t\")\n",
    "df_test = pd.read_csv(test_file_path, sep=\"\\t\")\n",
    "df_test.drop([\"Unnamed: 0\"], axis=1, inplace=True, errors='ignore')\n",
    "df_validation = pd.read_csv(val_file_path, sep=\"\\t\")\n",
    "df_seen = pd.concat([df_train, df_validation])\n",
    "df_levenshtein = pd.read_csv(f\"{levenshtein_data_path}/beta_{precision}_levenshtein.tsv\", sep=\"\\t\") #  remove if levenshtein data isn't available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_filename = f\"/home/ubuntu/BA_ZHAW/data/EDA/beta/ydata_profiling_{precision}.html\"\n",
    "df = pd.concat([df_train, df_test, df_validation])\n",
    "df = df.drop(columns=[\"TCR_name\", \"TRAV\", \"TRAJ\", \"TRA_CDR3\", \"TRAC\", \"TRBC\", \"TRA_CDR3\"], errors='ignore') # not interesting for analyze of beta chain\n",
    "print(f\"the whole dataset has {len(df)} entries and the following columns are considered for this notebook:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Profiling\n",
    "pandas-profiling package naming was changed. To continue profiling data use ydata-profiling instead!\n",
    "-> That's why we use ydata-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "profile = ProfileReport(df, title=\"Profiling Report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#profile.to_widgets()\n",
    "profile.to_file(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(df_levenshtein, title=f\"Report paired levenshtein {precision}\")\n",
    "levenshtein_data_path = f\"/home/ubuntu/BA_ZHAW/data/EDA/beta/\"\n",
    "profile.to_file(f\"{levenshtein_data_path}/profiling_{precision}_levenshtein.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Each entry has a minimum levenshtein to the seen data. From this values, we take the mean.\")\n",
    "\n",
    "df_levenshtein_TPP2 = df_levenshtein[df_levenshtein[\"task\"] == \"TPP2\"]\n",
    "print(f\"mean levenshtein distance of TRB TPP2: {df_levenshtein_TPP2['min_levenshtein_cdr_to_seen'].mean()}\")\n",
    "print(f\"mean levenshtein distance of Epitope TPP2: {df_levenshtein_TPP2['min_levenshtein_epitope_to_seen'].mean()}\")\n",
    "\n",
    "df_levenshtein_TPP3 = df_levenshtein[df_levenshtein[\"task\"] == \"TPP3\"]\n",
    "print(f\"mean levenshtein distance of TRB TPP3: {df_levenshtein_TPP3['min_levenshtein_cdr_to_seen'].mean()}\")\n",
    "print(f\"mean levenshtein distance of Epitope TPP3: {df_levenshtein_TPP3['min_levenshtein_epitope_to_seen'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epitopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_epitope_count = df[\"Epitope\"].value_counts().count()\n",
    "epitope_count = df[\"Epitope\"].notnull().sum()\n",
    "print(f\"there are {epitope_count} epitopes and {unique_epitope_count} distinct epitopes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df[\"Epitope\"].drop_duplicates(keep=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_test[df_test['task'] == 'TPP3']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a visualisation of how the epitopes are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each Epitope\n",
    "epitope_counts = df['Epitope'].value_counts()\n",
    "\n",
    "# Filter Epitopes that have more than 2 entries\n",
    "filtered_epitope_counts = epitope_counts[epitope_counts > 100]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "filtered_epitope_counts.plot(kind='bar', color='teal')\n",
    "plt.xlabel('Epitope')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Epitopes with More Than 100 Entries')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CDR-3 Regions (beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cdr_count = df[\"TRB_CDR3\"].value_counts().count()\n",
    "print(f\"there are {unique_cdr_count} unique CDR-3 beta regions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of TRB_CDR3 Sequence Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate TRB_CDR3 sequence lengths\n",
    "df['TRB_CDR3_Length'] = df['TRB_CDR3'].apply(len)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['TRB_CDR3_Length'])\n",
    "plt.title('Distribution of TRB_CDR3 Sequence Lengths')\n",
    "plt.xlabel('TRB_CDR3 Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V and J region (beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many entries do have V **and** J region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_VJ_count = df[[\"TRBV\", \"TRBJ\"]].notnull().all(axis=1).sum()\n",
    "print(f\"There are {paired_VJ_count} entries which have the V and J region\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visual representation of the distribution of V and J regions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to categorize each entry\n",
    "def categorize_row(row):\n",
    "    if pd.notnull(row['TRBV']) and pd.notnull(row['TRBJ']):\n",
    "        return 'Both V & J Regions'\n",
    "    elif pd.notnull(row['TRBV']):\n",
    "        return 'Only V Region'\n",
    "    elif pd.notnull(row['TRBJ']):\n",
    "        return 'Only J Region'\n",
    "    else:\n",
    "        return 'Neither'\n",
    "\n",
    "# Apply the function to each row\n",
    "df['Category'] = df.apply(categorize_row, axis=1)\n",
    "\n",
    "# Count the number of entries in each category\n",
    "category_counts = df['Category'].value_counts()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.pie(category_counts, labels=category_counts.index, autopct='%1.1f%%', startangle=140, colors=['skyblue', 'lightgreen', 'orange', 'lightcoral'])\n",
    "plt.title('Distribution of Entries by V & J Region Presence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring how many unique combinations of TRBV and TRBJ genes there are could be informative. This might help in understanding the diversity of T-cell receptor beta chains represented in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique TRBV and TRBJ combinations\n",
    "unique_combinations = df.groupby(['TRBV', 'TRBJ']).size().reset_index(name='Count')\n",
    "\n",
    "# Plotting the top 20 most frequent combinations\n",
    "top_combinations = unique_combinations.sort_values(by='Count', ascending=False).head(20)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(top_combinations['TRBV'] + '-' + top_combinations['TRBJ'], top_combinations['Count'], color='purple')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('TRBV-TRBJ Combinations')\n",
    "plt.title('Top 20 TRBV and TRBJ Combinations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V Region\n",
    "How many entries do have a V region and how many different V regions are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_V_count = df['TRBV'].nunique()\n",
    "print(f\"There are {unique_V_count} unique V regions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_count = df[\"TRBV\"].notnull().sum()\n",
    "print(f\"There are {V_count} entries for J region\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### J Region\n",
    "How many entries do have J region and how many different J regions are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_J_count = df[\"TRBJ\"].nunique()\n",
    "print(f\"There are {unique_J_count} unique J regions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_count = df[\"TRBJ\"].notnull().sum()\n",
    "print(f\"There are {J_count} entries for J region\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MHC\n",
    "How many entries do have MHC A **and** MHC B value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_MHC_count = df[[\"MHC\"]].notnull().all(axis=1).sum()\n",
    "print(f\"There are {paired_MHC_count} entries which have the MHC region\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_MHC_count = df[\"MHC\"].nunique()\n",
    "print(f\"There are {unique_MHC_count} unique MHC values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MHC_count = df[\"MHC\"].notnull().sum()\n",
    "print(f\"There are {MHC_count} entries MHC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of MHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each MHC\n",
    "mhc_counts = df['MHC'].value_counts()\n",
    "\n",
    "# Filter Epitopes that have more than 2 entries\n",
    "filtered_mhc_counts = mhc_counts[mhc_counts > 100]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "filtered_mhc_counts.plot(kind='bar', color='teal')\n",
    "plt.xlabel('MHC')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of MHC with More Than 10 Entries')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BA24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
