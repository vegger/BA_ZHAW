{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Levenshtein import distance\n",
    "import wandb\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pandarallel import pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# W&B Setup\n",
    "# -----------------------------------------------------------------------------\n",
    "load_dotenv()\n",
    "PROJECT_NAME = os.getenv(\"MAIN_PROJECT_NAME\")\n",
    "print(f\"PROJECT_NAME: {PROJECT_NAME}\")\n",
    "run = wandb.init(project=PROJECT_NAME, job_type=f\"download dataset\", entity=\"ba-zhaw\")\n",
    "config = wandb.config\n",
    "\n",
    "\n",
    "# Download corresponding artifact (= dataset) from W&B\n",
    "precision = \"allele\" # gene or allele\n",
    "download_path = \"/home/ubuntu/BA_ZHAW/data/WnB_Download/paired\"\n",
    "output_path = f'/home/ubuntu/BA_ZHAW/data/EDA/paired/'\n",
    "output_file_name = f'paired_{precision}_levenshtein_reclassified.tsv'\n",
    "dataset_name = f\"paired_{precision}\"\n",
    "artifact = run.use_artifact(f\"{dataset_name}:latest\")\n",
    "data_dir = artifact.download(download_path)\n",
    "\n",
    "run.finish()\n",
    "\n",
    "train_file_path = f\"{data_dir}/{precision}/train.tsv\"\n",
    "test_file_path = f\"{data_dir}/{precision}/test_reclassified_paired_specific.tsv\" # because seen in this case is either alpha or beta chain\n",
    "val_file_path = f\"{data_dir}/{precision}/validation.tsv\"\n",
    "\n",
    "n = 2000\n",
    "df_train = pd.read_csv(train_file_path, sep=\"\\t\")\n",
    "#df_test = pd.read_csv(test_file_path, sep=\"\\t\")\n",
    "df_test = pd.read_csv(test_file_path, sep=\"\\t\", skiprows=lambda i: i % n != 0)\n",
    "df_validation = pd.read_csv(val_file_path, sep=\"\\t\")\n",
    "df_seen = pd.concat([df_train, df_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levenshtein_min_column_cdr_alpha = 'min_levenshtein_cdr_alpha_to_seen'\n",
    "levenshtein_min_column_cdr_beta = 'min_levenshtein_cdr_beta_to_seen'\n",
    "levenshtein_min_column_epitope = 'min_levenshtein_epitope_to_seen'\n",
    "levenshtein_max_column_cdr_alpha = 'max_levenshtein_cdr_alpha_to_seen'\n",
    "levenshtein_max_column_cdr_beta = 'max_levenshtein_cdr_beta_to_seen'\n",
    "levenshtein_max_column_epitope = 'max_levenshtein_epitope_to_seen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[levenshtein_min_column_cdr_alpha] = 0\n",
    "df_test[levenshtein_min_column_cdr_beta] = 0\n",
    "df_test[levenshtein_min_column_epitope] = 0\n",
    "df_test[levenshtein_max_column_cdr_alpha] = 0\n",
    "df_test[levenshtein_max_column_cdr_beta] = 0\n",
    "df_test[levenshtein_max_column_epitope] = 0\n",
    "\n",
    "def set_levenshtein(row):\n",
    "  min_levenshtein_cdr_alpha = 100 # start value\n",
    "  min_levenshtein_cdr_beta = 100 # start value\n",
    "  min_levenshtein_epitope = 100 # start value\n",
    "  max_levenshtein_cdr_alpha = 0 # start value\n",
    "  max_levenshtein_cdr_beta = 0 # start value\n",
    "  max_levenshtein_epitope = 0 # start value\n",
    "\n",
    "  alpha_val = row['TRA_CDR3']\n",
    "  beta_val = row['TRB_CDR3']\n",
    "\n",
    "  for index, row_seen in df_seen.iterrows():\n",
    "    # cdr3 distance \n",
    "    cdr_alpha_distance = distance(alpha_val, row_seen['TRA_CDR3'])\n",
    "    cdr_beta_distance = distance(beta_val, row_seen['TRB_CDR3'])\n",
    "\n",
    "    if min_levenshtein_cdr_alpha > cdr_alpha_distance:\n",
    "      min_levenshtein_cdr_alpha = cdr_alpha_distance\n",
    "\n",
    "    if min_levenshtein_cdr_beta > cdr_beta_distance:\n",
    "      min_levenshtein_cdr_beta = cdr_beta_distance\n",
    "\n",
    "    if max_levenshtein_cdr_alpha < cdr_alpha_distance:\n",
    "      max_levenshtein_cdr_alpha = cdr_alpha_distance\n",
    "\n",
    "    if max_levenshtein_cdr_beta < cdr_beta_distance:\n",
    "      max_levenshtein_cdr_beta = cdr_beta_distance\n",
    "    \n",
    "    # epitope distance\n",
    "    epitope_distance = distance(row['Epitope'], row_seen['Epitope'])\n",
    "    \n",
    "    if min_levenshtein_epitope > epitope_distance:\n",
    "      min_levenshtein_epitope = epitope_distance\n",
    "  \n",
    "    if max_levenshtein_epitope < epitope_distance:\n",
    "      max_levenshtein_epitope = epitope_distance\n",
    "  \n",
    "  print(f\"Levenshtein distance (Task {row['task']}) min_cdr3_alpha={min_levenshtein_cdr_alpha}, min_cdr3_beta={min_levenshtein_cdr_beta}, max_cdr3_alpha={max_levenshtein_cdr_alpha}, max_cdr3_beta={max_levenshtein_cdr_beta}, epitope={min_levenshtein_epitope}\")\n",
    "\n",
    "  if row['task'] == 'TPP1' and ((min_levenshtein_cdr_alpha != 0 and min_levenshtein_cdr_beta != 0) or min_levenshtein_epitope != 0):\n",
    "    raise Exception(\"Levenshtein distance from seen data is not 0!\")\n",
    "  if row['task'] == 'TPP2' and ((min_levenshtein_cdr_alpha == 0 or min_levenshtein_cdr_beta == 0) or min_levenshtein_epitope != 0):\n",
    "    raise Exception(\"Error in TPP2 classification!\")\n",
    "  if row['task'] == 'TPP3' and ((min_levenshtein_cdr_alpha == 0 or min_levenshtein_cdr_beta == 0) or min_levenshtein_epitope == 0):\n",
    "    raise Exception(\"Error in TPP3 classification!\")\n",
    "  if row['task'] == 'TPP4' and (min_levenshtein_cdr_alpha != 0 and min_levenshtein_cdr_beta != 0 or min_levenshtein_epitope == 0):\n",
    "    raise Exception(\"Levenshtein distance from unseen data is 0!\")\n",
    "  \n",
    "  return pd.Series([min_levenshtein_cdr_alpha, max_levenshtein_cdr_alpha, min_levenshtein_cdr_beta, max_levenshtein_cdr_beta, min_levenshtein_epitope, max_levenshtein_epitope])\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "df_test[[levenshtein_min_column_cdr_alpha, levenshtein_max_column_cdr_alpha, levenshtein_min_column_cdr_beta, levenshtein_max_column_cdr_beta, levenshtein_min_column_epitope, levenshtein_max_column_epitope]] = df_test.parallel_apply(lambda x: set_levenshtein(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_path):\n",
    "  os.makedirs(output_path)\n",
    "df_test.to_csv(f'{output_path}/{output_file_name}', sep=\"\\t\", index=False)\n",
    "print(\"FINISHED SKRIPT\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
