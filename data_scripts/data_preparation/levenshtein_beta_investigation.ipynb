{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Levenshtein import distance\n",
    "import wandb\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pandarallel import pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# W&B Setup\n",
    "# -----------------------------------------------------------------------------\n",
    "load_dotenv()\n",
    "PROJECT_NAME = os.getenv(\"MAIN_PROJECT_NAME\")\n",
    "print(f\"PROJECT_NAME: {PROJECT_NAME}\")\n",
    "run = wandb.init(project=PROJECT_NAME, job_type=f\"download dataset\", entity=\"ba-zhaw\")\n",
    "config = wandb.config\n",
    "\n",
    "\n",
    "# Download corresponding artifact (= dataset) from W&B\n",
    "precision = \"allele\" # gene or allele\n",
    "download_path = \"/home/ubuntu/BA_ZHAW/data/WnB_Download/beta\"\n",
    "output_path = f'/home/ubuntu/BA_ZHAW/data/EDA/beta/'\n",
    "output_file_name = f'beta_{precision}_levenshtein.tsv'\n",
    "dataset_name = f\"beta_{precision}\"\n",
    "artifact = run.use_artifact(f\"{dataset_name}:latest\")\n",
    "data_dir = artifact.download(download_path)\n",
    "\n",
    "run.finish()\n",
    "\n",
    "train_file_path = f\"{data_dir}/{precision}/train.tsv\"\n",
    "test_file_path = f\"{data_dir}/{precision}/test.tsv\"\n",
    "val_file_path = f\"{data_dir}/{precision}/validation.tsv\"\n",
    "\n",
    "n = 10000\n",
    "df_train = pd.read_csv(train_file_path, sep=\"\\t\")\n",
    "#df_test = pd.read_csv(test_file_path, sep=\"\\t\")\n",
    "df_test = pd.read_csv(test_file_path, sep=\"\\t\", skiprows=lambda i: i % n != 0)\n",
    "df_test.drop([\"Unnamed: 0\"], axis=1, inplace=True, errors='ignore')\n",
    "df_validation = pd.read_csv(val_file_path, sep=\"\\t\")\n",
    "df_seen = pd.concat([df_train, df_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levenshtein_min_column_cdr = 'min_levenshtein_cdr_to_seen'\n",
    "levenshtein_min_column_epitope = 'min_levenshtein_epitope_to_seen'\n",
    "levenshtein_max_column_cdr = 'max_levenshtein_cdr_to_seen'\n",
    "levenshtein_max_column_epitope = 'max_levenshtein_epitope_to_seen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[levenshtein_min_column_cdr] = 0\n",
    "df_test[levenshtein_min_column_epitope] = 0\n",
    "df_test[levenshtein_max_column_cdr] = 0\n",
    "df_test[levenshtein_max_column_epitope] = 0\n",
    "\n",
    "def set_levenshtein(row):\n",
    "  min_levenshtein_cdr = 100 # start value\n",
    "  min_levenshtein_epitope = 100 # start value\n",
    "  max_levenshtein_cdr = 0 # start value\n",
    "  max_levenshtein_epitope = 0 # start value\n",
    "\n",
    "  for index, row_seen in df_seen.iterrows():\n",
    "    # cdr3 distance \n",
    "    cdr_distance = distance(row['TRB_CDR3'], row_seen['TRB_CDR3'])\n",
    "\n",
    "    if min_levenshtein_cdr > cdr_distance:\n",
    "      min_levenshtein_cdr = cdr_distance\n",
    "\n",
    "    if max_levenshtein_cdr < cdr_distance:\n",
    "      max_levenshtein_cdr = cdr_distance\n",
    "    \n",
    "    # epitope distance\n",
    "    epitope_distance = distance(row['Epitope'], row_seen['Epitope'])\n",
    "    \n",
    "    if min_levenshtein_epitope > epitope_distance:\n",
    "      min_levenshtein_epitope = epitope_distance\n",
    "  \n",
    "    if max_levenshtein_epitope < epitope_distance:\n",
    "      max_levenshtein_epitope = epitope_distance\n",
    "  \n",
    "  print(f\"Levenshtein distance (Task {row['task']}) cdr3={min_levenshtein_cdr}, epitope={min_levenshtein_epitope}\")\n",
    "  if row['task'] == 'TPP1' and (min_levenshtein_cdr != 0 or min_levenshtein_epitope != 0):\n",
    "    raise Exception(\"Levenshtein distance from seen data is not 0!\")\n",
    "  if row['task'] == 'TPP2' and (min_levenshtein_cdr == 0 or min_levenshtein_epitope != 0):\n",
    "    raise Exception(\"Error in TPP2 classification!\")\n",
    "  if row['task'] == 'TPP3' and (min_levenshtein_cdr == 0 or min_levenshtein_epitope == 0):\n",
    "    raise Exception(\"Error in TPP3 classification!\")\n",
    "  if row['task'] == 'TPP4' and (min_levenshtein_cdr != 0 or min_levenshtein_epitope == 0):\n",
    "    raise Exception(\"Levenshtein distance from unseen data is 0!\")\n",
    "  \n",
    "  return pd.Series([min_levenshtein_cdr, max_levenshtein_cdr, min_levenshtein_epitope, max_levenshtein_epitope])\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "df_test[[levenshtein_min_column_cdr, levenshtein_max_column_cdr, levenshtein_min_column_epitope, levenshtein_max_column_epitope]] = df_test.parallel_apply(lambda x: set_levenshtein(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_path):\n",
    "  os.makedirs(output_path)\n",
    "df_test.to_csv(f'{output_path}/{output_file_name}', sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
